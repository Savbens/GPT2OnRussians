{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7193d3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"roneneldan/TinyStories\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f8e66b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'One day, a little girl named Lily found a needle in her room. She knew it was difficult to play with it because it was sharp. Lily wanted to share the needle with her mom, so she could sew a button on her shirt.\\n\\nLily went to her mom and said, \"Mom, I found this needle. Can you share it with me and sew my shirt?\" Her mom smiled and said, \"Yes, Lily, we can share the needle and fix your shirt.\"\\n\\nTogether, they shared the needle and sewed the button on Lily\\'s shirt. It was not difficult for them because they were sharing and helping each other. After they finished, Lily thanked her mom for sharing the needle and fixing her shirt. They both felt happy because they had shared and worked together.'}\n"
     ]
    }
   ],
   "source": [
    "print(ds[\"train\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbb1c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• –°–∫–∞—á–∏–≤–∞–µ–º –º–æ–¥–µ–ª—å –∏ —Ç–æ–∫–µ–Ω–∞–π–∑–µ—Ä...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\–ü–æ–ª—å–∑–æ–≤–∞—Ç–∫–ª—å\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\marian\\tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n",
      "c:\\Users\\–ü–æ–ª—å–∑–æ–≤–∞—Ç–∫–ª—å\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤: ./opus-mt-en-ru\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\–ü–æ–ª—å–∑–æ–≤–∞—Ç–∫–ª—å\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\modeling_utils.py:3339: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[62517]]}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "\n",
    "\n",
    "model_id = \"Helsinki-NLP/opus-mt-en-ru\"\n",
    "save_dir = \"./opus-mt-en-ru\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "print(\"üì• –°–∫–∞—á–∏–≤–∞–µ–º –º–æ–¥–µ–ª—å –∏ —Ç–æ–∫–µ–Ω–∞–π–∑–µ—Ä...\")\n",
    "tokenizer = MarianTokenizer.from_pretrained(model_id, cache_dir=save_dir)\n",
    "model = MarianMTModel.from_pretrained(model_id, cache_dir=save_dir)\n",
    "\n",
    "print(\"üíæ –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤:\", save_dir)\n",
    "tokenizer.save_pretrained(save_dir)\n",
    "model.save_pretrained(save_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d310bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìò –ü—Ä–∏–º–µ—Ä –ø–µ—Ä–µ–≤–æ–¥–∞:\n",
      "EN: –ü—Ä–∏–≤–µ—Ç, –∫–∞–∫ –¥–µ–ª–∞?\n",
      "RU: –ü–æ–Ω–∏–º–∞–µ—à—å, –ö–µ–∫ –¢–µ–ª–ª–∞?\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\nüìò –ü—Ä–∏–º–µ—Ä –ø–µ—Ä–µ–≤–æ–¥–∞:\")\n",
    "sample_text = [\"Hello, how are you\"]\n",
    "inputs = tokenizer(sample_text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "translated = model.generate(**inputs)\n",
    "output = tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
    "\n",
    "print(\"EN:\", sample_text[0])\n",
    "print(\"RU:\", output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675ca12d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÅ –ü–µ—Ä–µ–≤–æ–¥–∏–º –∏—Å—Ç–æ—Ä–∏–∏...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [31:59<00:00,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Ñ–∞–π–ª: translated_tiny_stories.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7589c059a624a469a77e9697d36b91e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ –ì–æ—Ç–æ–≤–æ! 1000 –∏—Å—Ç–æ—Ä–∏–π –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–æ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "dataset = load_dataset(\"roneneldan/TinyStories\", split=\"train[:1000]\")\n",
    "\n",
    "translated_data = []\n",
    "\n",
    "print(\"üîÅ –ü–µ—Ä–µ–≤–æ–¥–∏–º –∏—Å—Ç–æ—Ä–∏–∏...\")\n",
    "for example in tqdm(dataset, total=1000):\n",
    "    text = example[\"text\"]\n",
    "    inputs = tokenizer([text], return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)\n",
    "    translated_tokens = model.generate(**inputs, max_length=512)\n",
    "    translated_text = tokenizer.batch_decode(translated_tokens, skip_special_tokens=True)[0]\n",
    "\n",
    "    translated_data.append({\n",
    "        \"original\": text,\n",
    "        \"translation\": translated_text\n",
    "    })\n",
    "\n",
    "\n",
    "new_dataset = Dataset.from_list(translated_data)\n",
    "\n",
    "\n",
    "print(\"üíæ –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Ñ–∞–π–ª: translated_tiny_stories.jsonl\")\n",
    "new_dataset.to_json(\"translated_tiny_stories.jsonl\", orient=\"records\", lines=True, force_ascii=False)\n",
    "\n",
    "print(\"1000 –∏—Å—Ç–æ—Ä–∏–π –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–æ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
